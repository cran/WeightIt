<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Noah Greifer" />

<meta name="date" content="2022-06-24" />

<title>Using WeightIt to Estimate Balancing Weights</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Using WeightIt to Estimate Balancing
Weights</h1>
<h4 class="author">Noah Greifer</h4>
<h4 class="date">2022-06-24</h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p><code>WeightIt</code> contains several functions for estimating and
assessing balancing weights for observational studies. These weights can
be used to estimate the causal parameters of marginal structural models.
I will not go into the basics of causal inference methods here. For good
introductory articles, see <span class="citation">Austin (<a href="#ref-austinIntroductionPropensityScore2011" role="doc-biblioref">2011</a>)</span>, <span class="citation">Austin and
Stuart (<a href="#ref-austinMovingBestPractice2015" role="doc-biblioref">2015</a>)</span>, <span class="citation">Robins,
Hernán, and Brumback (<a href="#ref-robinsMarginalStructuralModels2000" role="doc-biblioref">2000</a>)</span>, or <span class="citation">Thoemmes and Ong (<a href="#ref-thoemmesPrimerInverseProbability2016" role="doc-biblioref">2016</a>)</span>.</p>
<p>Typically, the analysis of an observation study might proceed as
follows: identify the covariates for which balance is required; assess
the quality of the data available, including missingness and measurement
error; estimate weights that balance the covariates adequately; and
estimate a treatment effect and corresponding standard error or
confidence interval. This guide will go through all these steps for two
observational studies: estimating the causal effect of a point treatment
on an outcome, and estimating the causal parameters of a marginal
structural model with multiple treatment periods. This is not meant to
be a definitive guide, but rather an introduction to the relevant
issues.</p>
</div>
<div id="estimating-the-effect-of-a-point-treatment" class="section level2">
<h2>Estimating the Effect of a Point Treatment</h2>
<p>First we will use the Lalonde dataset to estimate the effect of a
point treatment. We’ll use the version of the data set that resides
within the <code>cobalt</code> package, which we will use later on as
well. Here, we are interested in the average treatment effect on the
treated (ATT).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;lalonde&quot;</span>, <span class="at">package =</span> <span class="st">&quot;cobalt&quot;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(lalonde)</span></code></pre></div>
<div class="kable-table">
<table>
<thead>
<tr class="header">
<th align="right">treat</th>
<th align="right">age</th>
<th align="right">educ</th>
<th align="left">race</th>
<th align="right">married</th>
<th align="right">nodegree</th>
<th align="right">re74</th>
<th align="right">re75</th>
<th align="right">re78</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">37</td>
<td align="right">11</td>
<td align="left">black</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">9930.0460</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">22</td>
<td align="right">9</td>
<td align="left">hispan</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3595.8940</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">30</td>
<td align="right">12</td>
<td align="left">black</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">24909.4500</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">27</td>
<td align="right">11</td>
<td align="left">black</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">7506.1460</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">33</td>
<td align="right">8</td>
<td align="left">black</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">289.7899</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">22</td>
<td align="right">9</td>
<td align="left">black</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">4056.4940</td>
</tr>
</tbody>
</table>
</div>
<p>We have our outcome (<code>re78</code>), our treatment
(<code>treat</code>), and the covariates for which balance is desired
(<code>age</code>, <code>educ</code>, <code>race</code>,
<code>married</code>, <code>nodegree</code>, <code>re74</code>, and
<code>re75</code>). Using <code>cobalt</code>, we can examine the
initial imbalance on the covariates:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;cobalt&quot;</span>)</span></code></pre></div>
<pre><code>##  cobalt (Version 4.3.2, Build Date: 2022-01-19)</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bal.tab</span>(treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> race <span class="sc">+</span> married <span class="sc">+</span> nodegree <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">data =</span> lalonde, <span class="at">estimand =</span> <span class="st">&quot;ATT&quot;</span>, <span class="at">thresholds =</span> <span class="fu">c</span>(<span class="at">m =</span> .<span class="dv">05</span>))</span></code></pre></div>
<pre><code>## Balance Measures
##                Type Diff.Un      M.Threshold.Un
## age         Contin. -0.3094 Not Balanced, &gt;0.05
## educ        Contin.  0.0550 Not Balanced, &gt;0.05
## race_black   Binary  0.6404 Not Balanced, &gt;0.05
## race_hispan  Binary -0.0827 Not Balanced, &gt;0.05
## race_white   Binary -0.5577 Not Balanced, &gt;0.05
## married      Binary -0.3236 Not Balanced, &gt;0.05
## nodegree     Binary  0.1114 Not Balanced, &gt;0.05
## re74        Contin. -0.7211 Not Balanced, &gt;0.05
## re75        Contin. -0.2903 Not Balanced, &gt;0.05
## 
## Balance tally for mean differences
##                     count
## Balanced, &lt;0.05         0
## Not Balanced, &gt;0.05     9
## 
## Variable with the greatest mean difference
##  Variable Diff.Un      M.Threshold.Un
##      re74 -0.7211 Not Balanced, &gt;0.05
## 
## Sample sizes
##     Control Treated
## All     429     185</code></pre>
<p>Based on this output, we can see that all variables are imbalanced in
the sense that the standardized mean differences (for continuous
variables) and differences in proportion (for binary variables) are
greater than .05 for all variables. In particular, <code>re74</code> and
<code>re75</code> are quite imbalanced, which is troubling given that
they are likely strong predictors of the outcome. We will estimate
weights using <code>weightit()</code> to try to attain balance on these
covariates.</p>
<p>First, we’ll start simple, and use inverse probability weights from
propensity scores generated through logistic regression. We need to
supply <code>weightit()</code> with the formula for the model, the data
set, the estimand (ATT), and the method of estimation
(<code>&quot;ps&quot;</code>) for propensity score weights).</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;WeightIt&quot;</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>W.out <span class="ot">&lt;-</span> <span class="fu">weightit</span>(treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> race <span class="sc">+</span> married <span class="sc">+</span> nodegree <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> lalonde, <span class="at">estimand =</span> <span class="st">&quot;ATT&quot;</span>, <span class="at">method =</span> <span class="st">&quot;ps&quot;</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>W.out <span class="co">#print the output</span></span></code></pre></div>
<pre><code>## A weightit object
##  - method: &quot;ps&quot; (propensity score weighting)
##  - number of obs.: 614
##  - sampling weights: none
##  - treatment: 2-category
##  - estimand: ATT (focal: 1)
##  - covariates: age, educ, race, married, nodegree, re74, re75</code></pre>
<p>Printing the output of <code>weightit()</code> displays a summary of
how the weights were estimated. Let’s examine the quality of the weights
using <code>summary()</code>. Weights with low variability are desirable
because they improve the precision of the estimator. This variability is
presented in several ways: by the ratio of the largest weight to the
smallest in each group, the coefficient of variation (standard deviation
divided by the mean) of the weights in each group, and the effective
sample size computed from the weights. We want a small ratio, a smaller
coefficient of variation, and a large effective sample size (ESS). What
constitutes these values is mostly relative, though, and must be
balanced with other constraints, including covariate balance. These
metrics are best used when comparing weighting methods, but the ESS can
give a sense of how much information remains in the weighted sample on a
familiar scale.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(W.out)</span></code></pre></div>
<pre><code>##                  Summary of weights
## 
## - Weight ranges:
## 
##            Min                                  Max
## treated 1.0000         ||                    1.0000
## control 0.0092 |---------------------------| 3.7432
## 
## - Units with 5 most extreme weights by group:
##                                            
##               5      4      3      2      1
##  treated      1      1      1      1      1
##             597    573    381    411    303
##  control 3.0301 3.0592 3.2397 3.5231 3.7432
## 
## - Weight statistics:
## 
##         Coef of Var   MAD Entropy # Zeros
## treated       0.000 0.000  -0.000       0
## control       1.818 1.289   1.098       0
## 
## - Effective Sample Sizes:
## 
##            Control Treated
## Unweighted  429.       185
## Weighted     99.82     185</code></pre>
<p>These weights have quite high variability, and yield an ESS of close
to 100 in the control group. Let’s see if these weights managed to yield
balance on our covariates.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bal.tab</span>(W.out, <span class="at">stats =</span> <span class="fu">c</span>(<span class="st">&quot;m&quot;</span>, <span class="st">&quot;v&quot;</span>), <span class="at">thresholds =</span> <span class="fu">c</span>(<span class="at">m =</span> .<span class="dv">05</span>))</span></code></pre></div>
<pre><code>## Call
##  weightit(formula = treat ~ age + educ + race + married + nodegree + 
##     re74 + re75, data = lalonde, method = &quot;ps&quot;, estimand = &quot;ATT&quot;)
## 
## Balance Measures
##                 Type Diff.Adj         M.Threshold V.Ratio.Adj
## prop.score  Distance  -0.0205     Balanced, &lt;0.05      1.0324
## age          Contin.   0.1188 Not Balanced, &gt;0.05      0.4578
## educ         Contin.  -0.0284     Balanced, &lt;0.05      0.6636
## race_black    Binary  -0.0022     Balanced, &lt;0.05           .
## race_hispan   Binary   0.0002     Balanced, &lt;0.05           .
## race_white    Binary   0.0021     Balanced, &lt;0.05           .
## married       Binary   0.0186     Balanced, &lt;0.05           .
## nodegree      Binary   0.0184     Balanced, &lt;0.05           .
## re74         Contin.  -0.0021     Balanced, &lt;0.05      1.3206
## re75         Contin.   0.0110     Balanced, &lt;0.05      1.3938
## 
## Balance tally for mean differences
##                     count
## Balanced, &lt;0.05         9
## Not Balanced, &gt;0.05     1
## 
## Variable with the greatest mean difference
##  Variable Diff.Adj         M.Threshold
##       age   0.1188 Not Balanced, &gt;0.05
## 
## Effective sample sizes
##            Control Treated
## Unadjusted  429.       185
## Adjusted     99.82     185</code></pre>
<p>For nearly all the covariates, these weights yielded very good
balance. Only <code>age</code> remained imbalanced, with a standardized
mean difference greater than .05 and a variance ratio greater than 2.
Let’s see if we can do better. We’ll choose a different method: entropy
balancing <span class="citation">(<a href="#ref-hainmuellerEntropyBalancingCausal2012" role="doc-biblioref">Hainmueller 2012</a>)</span>, which guarantees
perfect balance on specified moments of the covariates while minimizing
the entropy (a measure of dispersion) of the weights.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>W.out <span class="ot">&lt;-</span> <span class="fu">weightit</span>(treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> race <span class="sc">+</span> married <span class="sc">+</span> nodegree <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> lalonde, <span class="at">estimand =</span> <span class="st">&quot;ATT&quot;</span>, <span class="at">method =</span> <span class="st">&quot;ebal&quot;</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(W.out)</span></code></pre></div>
<pre><code>##                  Summary of weights
## 
## - Weight ranges:
## 
##            Min                                  Max
## treated 1.0000    ||                         1.0000
## control 0.0188 |---------------------------| 9.4195
## 
## - Units with 5 most extreme weights by group:
##                                            
##               5      4      3      2      1
##  treated      1      1      1      1      1
##             608    381    597    303    411
##  control 7.1268 7.5013 7.9979 9.0355 9.4195
## 
## - Weight statistics:
## 
##         Coef of Var   MAD Entropy # Zeros
## treated       0.000 0.000   0.000       0
## control       1.834 1.287   1.101       0
## 
## - Effective Sample Sizes:
## 
##            Control Treated
## Unweighted  429.       185
## Weighted     98.46     185</code></pre>
<p>The variability of the weights has not changed much, but let’s see if
there are any gains in terms of balance:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bal.tab</span>(W.out, <span class="at">stats =</span> <span class="fu">c</span>(<span class="st">&quot;m&quot;</span>, <span class="st">&quot;v&quot;</span>), <span class="at">thresholds =</span> <span class="fu">c</span>(<span class="at">m =</span> .<span class="dv">05</span>))</span></code></pre></div>
<pre><code>## Call
##  weightit(formula = treat ~ age + educ + race + married + nodegree + 
##     re74 + re75, data = lalonde, method = &quot;ebal&quot;, estimand = &quot;ATT&quot;)
## 
## Balance Measures
##                Type Diff.Adj     M.Threshold V.Ratio.Adj
## age         Contin.        0 Balanced, &lt;0.05      0.4097
## educ        Contin.        0 Balanced, &lt;0.05      0.6636
## race_black   Binary        0 Balanced, &lt;0.05           .
## race_hispan  Binary       -0 Balanced, &lt;0.05           .
## race_white   Binary       -0 Balanced, &lt;0.05           .
## married      Binary       -0 Balanced, &lt;0.05           .
## nodegree     Binary       -0 Balanced, &lt;0.05           .
## re74        Contin.       -0 Balanced, &lt;0.05      1.3264
## re75        Contin.       -0 Balanced, &lt;0.05      1.3350
## 
## Balance tally for mean differences
##                     count
## Balanced, &lt;0.05         9
## Not Balanced, &gt;0.05     0
## 
## Variable with the greatest mean difference
##  Variable Diff.Adj     M.Threshold
##   married       -0 Balanced, &lt;0.05
## 
## Effective sample sizes
##            Control Treated
## Unadjusted  429.       185
## Adjusted     98.46     185</code></pre>
<p>Indeed, we have achieved perfect balance on the means of the
covariates. However, the variance ratio of <code>age</code> is still
quite high. We could continue to try to adjust for this imbalance, but
if there is reason to believe it is unlikely to affect the outcome, it
may be best to leave it as is. (You can try adding <code>I(age^2)</code>
to the formula and see what changes this causes.)</p>
<p>Now that we have our weights stored in <code>W.out</code>, let’s
extract them and estimate our treatment effect.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(survey)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>d.w <span class="ot">&lt;-</span> <span class="fu">svydesign</span>(<span class="sc">~</span><span class="dv">1</span>, <span class="at">weights =</span> W.out<span class="sc">$</span>weights, <span class="at">data =</span> lalonde)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">svyglm</span>(re78 <span class="sc">~</span> treat, <span class="at">design =</span> d.w)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fit)</span></code></pre></div>
<pre><code>## (Intercept)       treat 
##    5075.929    1273.215</code></pre>
<p>Now let’s do some inference. Although some authors recommend using
“robust” sandwich standard errors to adjust for the weights <span class="citation">(<a href="#ref-robinsMarginalStructuralModels2000" role="doc-biblioref">Robins, Hernán, and Brumback 2000</a>; <a href="#ref-hainmuellerEntropyBalancingCausal2012" role="doc-biblioref">Hainmueller 2012</a>)</span>, others believe these
can misleading and recommend bootstrapping instead <span class="citation">(<a href="#ref-reifeisVarianceTreatmentEffect2020" role="doc-biblioref">Reifeis and Hudgens 2020</a>; <a href="#ref-chanGloballyEfficientNonparametric2016" role="doc-biblioref">Chan, Yam, and Zhang 2016</a>)</span>. We’ll
examine both approaches.</p>
<p><code>svyglm()</code> in the survey package produces robust standard
errors, so we can use <code>summary()</code> to view the standard error
of the effect estimate.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Robust standard errors and confidence intervals</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## svyglm(formula = re78 ~ treat, design = d.w)
## 
## Survey design:
## svydesign(~1, weights = W.out$weights, data = lalonde)
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   5075.9      589.4   8.612   &lt;2e-16 ***
## treat         1273.2      825.1   1.543    0.123    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 45038738)
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(fit)</span></code></pre></div>
<pre><code>##                2.5 %   97.5 %
## (Intercept) 3918.409 6233.449
## treat       -347.069 2893.498</code></pre>
<p>Our confidence interval for <code>treat</code> contains 0, so there
isn’t evidence that <code>treat</code> has an effect on
<code>re78</code>.</p>
<p>Next let’s use bootstrapping to estimate confidence intervals. We
don’t need to use <code>svyglm()</code> and can simply use
<code>glm()</code> (or <code>lm()</code>) to compute the effect
estimates in each bootstrapped sample because we are not computing
standard errors, and the treatment effect estimates will be the
same.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Bootstrapping</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;boot&quot;</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>est.fun <span class="ot">&lt;-</span> <span class="cf">function</span>(data, index) {</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  W.out <span class="ot">&lt;-</span> <span class="fu">weightit</span>(treat <span class="sc">~</span> age <span class="sc">+</span> educ <span class="sc">+</span> race <span class="sc">+</span> married <span class="sc">+</span> nodegree <span class="sc">+</span> re74 <span class="sc">+</span> re75,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> data[index,], <span class="at">estimand =</span> <span class="st">&quot;ATT&quot;</span>, <span class="at">method =</span> <span class="st">&quot;ebal&quot;</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(re78 <span class="sc">~</span> treat, <span class="at">data =</span> data[index,], <span class="at">weights =</span> W.out<span class="sc">$</span>weights)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">coef</span>(fit)[<span class="st">&quot;treat&quot;</span>])</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>boot.out <span class="ot">&lt;-</span> <span class="fu">boot</span>(est.fun, <span class="at">data =</span> lalonde, <span class="at">R =</span> <span class="dv">999</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="fu">boot.ci</span>(boot.out, <span class="at">type =</span> <span class="st">&quot;bca&quot;</span>) <span class="co">#type shouldn&#39;t matter so much</span></span></code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 999 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boot.out, type = &quot;bca&quot;)
## 
## Intervals : 
## Level       BCa          
## 95%   (-421, 2886 )  
## Calculations and Intervals on Original Scale</code></pre>
<p>In this case, our confidence intervals were similar. Bootstrapping
can take some time, especially with weight estimation methods that take
longer, such as SuperLearner (<code>method = &quot;super&quot;</code>), covariate
balancing propensity score estimation (<code>method = &quot;cbps&quot;</code>), or
generalized boosted modeling (<code>method = &quot;gbm&quot;</code>).</p>
<p>If we wanted to produce a “doubly-robust” treatment effect estimate,
we could add baseline covariates to the <code>glm()</code> (or
<code>svyglm()</code>) model (in both the original effect estimation and
the confidence interval estimation).</p>
</div>
<div id="estimating-the-effect-of-a-longitudinal-treatment" class="section level2">
<h2>Estimating the Effect of a Longitudinal Treatment</h2>
<p><code>WeightIt</code> can estimate weights for longitudinal treatment
marginal structural models as well. This time, we’ll use the sample data
set from <code>twang</code> to estimate our weights. Data must be in
“wide” format; to go from long to wide, see the example at
<code>?weightitMSM</code>.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;iptwExWide&quot;</span>, <span class="at">package =</span> <span class="st">&quot;twang&quot;</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iptwExWide)</span></code></pre></div>
<div class="kable-table">
<table style="width:100%;">
<colgroup>
<col width="16%" />
<col width="10%" />
<col width="5%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">outcome</th>
<th align="right">gender</th>
<th align="right">age</th>
<th align="right">use0</th>
<th align="right">use1</th>
<th align="right">use2</th>
<th align="right">tx1</th>
<th align="right">tx2</th>
<th align="right">tx3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-0.2782802</td>
<td align="right">0</td>
<td align="right">43</td>
<td align="right">1.1349651</td>
<td align="right">0.4674825</td>
<td align="right">0.3174825</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">0.5319329</td>
<td align="right">0</td>
<td align="right">50</td>
<td align="right">1.1119318</td>
<td align="right">0.4559659</td>
<td align="right">0.4059659</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">-0.8173614</td>
<td align="right">1</td>
<td align="right">36</td>
<td align="right">-0.8707776</td>
<td align="right">-0.5353888</td>
<td align="right">-0.5853888</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">-0.1530853</td>
<td align="right">1</td>
<td align="right">63</td>
<td align="right">0.2107316</td>
<td align="right">0.0053658</td>
<td align="right">-0.1446342</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">-0.7344267</td>
<td align="right">0</td>
<td align="right">24</td>
<td align="right">0.0693956</td>
<td align="right">-0.0653022</td>
<td align="right">-0.1153022</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">-0.8519376</td>
<td align="right">1</td>
<td align="right">20</td>
<td align="right">-1.6626489</td>
<td align="right">-0.9313244</td>
<td align="right">-1.0813244</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
</div>
<p>We have our outcome variable (<code>outcome</code>), our time-stable
baseline variables (<code>gender</code> and <code>age</code>), our
pre-treatment time-varying variables (<code>use0</code>, measured before
the first treatment, <code>use1</code>, and <code>use2</code>), and our
three time-varying treatment variables (<code>tx1</code>,
<code>tx2</code>, and <code>tx3</code>). We are interested in the joint,
unique, causal effects of each treatment period on the outcome. At each
treatment time point, we need to achieve balance on all variables
measured prior to that treatment, including previous treatments.</p>
<p>Using <code>cobalt</code>, we can examine the initial imbalance at
each time point and overall:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;cobalt&quot;</span>) <span class="co">#if not already attached</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">bal.tab</span>(<span class="fu">list</span>(tx1 <span class="sc">~</span> age <span class="sc">+</span> gender <span class="sc">+</span> use0,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>             tx2 <span class="sc">~</span> tx1 <span class="sc">+</span> use1 <span class="sc">+</span> age <span class="sc">+</span> gender <span class="sc">+</span> use0,</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>             tx3 <span class="sc">~</span> tx2 <span class="sc">+</span> use2 <span class="sc">+</span> tx1 <span class="sc">+</span> use1 <span class="sc">+</span> age <span class="sc">+</span> gender <span class="sc">+</span> use0),</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">data =</span> iptwExWide, <span class="at">stats =</span> <span class="fu">c</span>(<span class="st">&quot;m&quot;</span>, <span class="st">&quot;ks&quot;</span>), <span class="at">thresholds =</span> <span class="fu">c</span>(<span class="at">m =</span> .<span class="dv">05</span>),</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">which.time =</span> .all)</span></code></pre></div>
<pre><code>## Balance by Time Point
## 
##  - - - Time: 1 - - - 
## Balance Measures
##           Type Diff.Un      M.Threshold.Un  KS.Un
## age    Contin.  0.3799 Not Balanced, &gt;0.05 0.2099
## gender  Binary  0.2945 Not Balanced, &gt;0.05 0.2945
## use0   Contin.  0.2668 Not Balanced, &gt;0.05 0.1681
## 
## Balance tally for mean differences
##                     count
## Balanced, &lt;0.05         0
## Not Balanced, &gt;0.05     3
## 
## Variable with the greatest mean difference
##  Variable Diff.Un      M.Threshold.Un
##       age  0.3799 Not Balanced, &gt;0.05
## 
## Sample sizes
##     Control Treated
## All     294     706
## 
##  - - - Time: 2 - - - 
## Balance Measures
##           Type Diff.Un      M.Threshold.Un  KS.Un
## tx1     Binary  0.1695 Not Balanced, &gt;0.05 0.1695
## use1   Contin.  0.0848 Not Balanced, &gt;0.05 0.0763
## age    Contin.  0.2240 Not Balanced, &gt;0.05 0.1331
## gender  Binary  0.1927 Not Balanced, &gt;0.05 0.1927
## use0   Contin.  0.1169 Not Balanced, &gt;0.05 0.0913
## 
## Balance tally for mean differences
##                     count
## Balanced, &lt;0.05         0
## Not Balanced, &gt;0.05     5
## 
## Variable with the greatest mean difference
##  Variable Diff.Un      M.Threshold.Un
##       age   0.224 Not Balanced, &gt;0.05
## 
## Sample sizes
##     Control Treated
## All     492     508
## 
##  - - - Time: 3 - - - 
## Balance Measures
##           Type Diff.Un      M.Threshold.Un  KS.Un
## tx2     Binary  0.2423 Not Balanced, &gt;0.05 0.2423
## use2   Contin.  0.1087 Not Balanced, &gt;0.05 0.1161
## tx1     Binary  0.1071 Not Balanced, &gt;0.05 0.1071
## use1   Contin.  0.1662 Not Balanced, &gt;0.05 0.1397
## age    Contin.  0.3431 Not Balanced, &gt;0.05 0.1863
## gender  Binary  0.1532 Not Balanced, &gt;0.05 0.1532
## use0   Contin.  0.1859 Not Balanced, &gt;0.05 0.1350
## 
## Balance tally for mean differences
##                     count
## Balanced, &lt;0.05         0
## Not Balanced, &gt;0.05     7
## 
## Variable with the greatest mean difference
##  Variable Diff.Un      M.Threshold.Un
##       age  0.3431 Not Balanced, &gt;0.05
## 
## Sample sizes
##     Control Treated
## All     415     585
##  - - - - - - - - - - -</code></pre>
<p><code>bal.tab()</code> indicates significant imbalance on most
covariates at most time points, so we need to do some work to eliminate
that imbalance in our weighted data set. We’ll use the
<code>weightitMSM()</code> function to specify our weight models. The
syntax is similar both to that of <code>weightit()</code> for point
treatments and to that of <code>bal.tab()</code> for longitudinal
treatments. We’ll use <code>method = &quot;ps&quot;</code> and
<code>stabilize = TRUE</code> for stabilized propensity score weights
estimated using logistic regression.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>Wmsm.out <span class="ot">&lt;-</span> <span class="fu">weightitMSM</span>(<span class="fu">list</span>(tx1 <span class="sc">~</span> age <span class="sc">+</span> gender <span class="sc">+</span> use0,</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>                             tx2 <span class="sc">~</span> tx1 <span class="sc">+</span> use1 <span class="sc">+</span> age <span class="sc">+</span> gender <span class="sc">+</span> use0,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>                             tx3 <span class="sc">~</span> tx2 <span class="sc">+</span> use2 <span class="sc">+</span> tx1 <span class="sc">+</span> use1 <span class="sc">+</span> age <span class="sc">+</span> gender <span class="sc">+</span> use0),</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span> iptwExWide, <span class="at">method =</span> <span class="st">&quot;ps&quot;</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">stabilize =</span> <span class="cn">TRUE</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>Wmsm.out</span></code></pre></div>
<pre><code>## A weightitMSM object
##  - method: &quot;ps&quot; (propensity score weighting)
##  - number of obs.: 1000
##  - sampling weights: none
##  - number of time points: 3 (tx1, tx2, tx3)
##  - treatment: 
##     + time 1: 2-category
##     + time 2: 2-category
##     + time 3: 2-category
##  - covariates: 
##     + baseline: age, gender, use0
##     + after time 1: tx1, use1, age, gender, use0
##     + after time 2: tx2, use2, tx1, use1, age, gender, use0
##  - stabilized; stabilization factors:
##     + baseline: (none)
##     + after time 1: tx1
##     + after time 2: tx1, tx2, tx1:tx2</code></pre>
<p>No matter which method is selected, <code>weightitMSM()</code>
estimates separate weights for each time period and then takes the
product of the weights for each individual to arrive at the final
estimated weights. Printing the output of <code>weightitMSM()</code>
provides some details about the function call and the output. We can
take a look at the quality of the weights with <code>summary()</code>,
just as we could for point treatments.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Wmsm.out)</span></code></pre></div>
<pre><code>##                  Summary of weights
## 
##                        Time 1                       
##                  Summary of weights
## 
## - Weight ranges:
## 
##            Min                                  Max
## treated 0.4767  |---------|                  3.8963
## control 0.2900 |---------------------------| 8.8680
## 
## - Units with 5 most extreme weights by group:
##                                            
##             348    951    715    657    442
##  treated 2.8052 2.9868 3.1041 3.3316 3.8963
##             206    518     95    282    547
##  control  3.405 3.6434  4.687  5.121  8.868
## 
## - Weight statistics:
## 
##         Coef of Var   MAD Entropy # Zeros
## treated       0.420 0.281   0.073       0
## control       0.775 0.423   0.183       0
## 
## - Mean of Weights = 1
## 
## - Effective Sample Sizes:
## 
##            Control Treated
## Unweighted  294.    706.  
## Weighted    183.85  600.26
## 
##                        Time 2                       
##                  Summary of weights
## 
## - Weight ranges:
## 
##            Min                                  Max
## treated 0.3911 |----------|                  3.8963
## control 0.2900 |---------------------------| 8.8680
## 
## - Units with 5 most extreme weights by group:
##                                            
##             951    980    715    657    442
##  treated 2.9868 3.0427 3.1041 3.3316 3.8963
##             206    518     95    282    547
##  control  3.405 3.6434  4.687  5.121  8.868
## 
## - Weight statistics:
## 
##         Coef of Var   MAD Entropy # Zeros
## treated       0.482 0.333   0.096       0
## control       0.598 0.309   0.113       0
## 
## - Mean of Weights = 1
## 
## - Effective Sample Sizes:
## 
##            Control Treated
## Unweighted  492.    508.  
## Weighted    362.67  412.39
## 
##                        Time 3                       
##                  Summary of weights
## 
## - Weight ranges:
## 
##            Min                                  Max
## treated 0.4767  |---------|                  3.8963
## control 0.2900 |---------------------------| 8.8680
## 
## - Units with 5 most extreme weights by group:
##                                           
##             109    715    657   206    442
##  treated 3.0238 3.1041 3.3316 3.405 3.8963
##             980    518     95   282    547
##  control 3.0427 3.6434  4.687 5.121  8.868
## 
## - Weight statistics:
## 
##         Coef of Var   MAD Entropy # Zeros
## treated       0.488 0.337   0.097       0
## control       0.609 0.300   0.115       0
## 
## - Mean of Weights = 1
## 
## - Effective Sample Sizes:
## 
##            Control Treated
## Unweighted   415.   585.  
## Weighted     302.9  472.55</code></pre>
<p>Displayed are summaries of how the weights perform at each time point
with respect to variability. Next, we’ll examine how well they perform
with respect to covariate balance.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bal.tab</span>(Wmsm.out, <span class="at">stats =</span> <span class="fu">c</span>(<span class="st">&quot;m&quot;</span>, <span class="st">&quot;ks&quot;</span>), <span class="at">thresholds =</span> <span class="fu">c</span>(<span class="at">m =</span> .<span class="dv">05</span>),</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">which.time =</span> .none)</span></code></pre></div>
<pre><code>## Call
##  weightitMSM(formula.list = list(tx1 ~ age + gender + use0, tx2 ~ 
##     tx1 + use1 + age + gender + use0, tx3 ~ tx2 + use2 + tx1 + 
##     use1 + age + gender + use0), data = iptwExWide, method = &quot;ps&quot;, 
##     stabilize = TRUE)
## 
## Balance summary across all time points
##              Times     Type Max.Diff.Adj         M.Threshold Max.KS.Adj
## prop.score 1, 2, 3 Distance       0.3217                         0.1748
## age        1, 2, 3  Contin.       0.0153     Balanced, &lt;0.05     0.0850
## gender     1, 2, 3   Binary       0.0214     Balanced, &lt;0.05     0.0214
## use0       1, 2, 3  Contin.       0.0549 Not Balanced, &gt;0.05     0.0952
## tx1           2, 3   Binary       0.1544 Not Balanced, &gt;0.05     0.1544
## use1          2, 3  Contin.       0.0495     Balanced, &lt;0.05     0.0547
## tx2              3   Binary       0.2396 Not Balanced, &gt;0.05     0.2396
## use2             3  Contin.       0.1012 Not Balanced, &gt;0.05     0.0697
## 
## Balance tally for mean differences
##                     count
## Balanced, &lt;0.05         3
## Not Balanced, &gt;0.05     4
## 
## Variable with the greatest mean difference
##  Variable Max.Diff.Adj         M.Threshold
##       tx2       0.2396 Not Balanced, &gt;0.05
## 
## Effective sample sizes
##  - Time 1
##            Control Treated
## Unadjusted  294.    706.  
## Adjusted    183.85  600.26
##  - Time 2
##            Control Treated
## Unadjusted  492.    508.  
## Adjusted    362.67  412.39
##  - Time 3
##            Control Treated
## Unadjusted   415.   585.  
## Adjusted     302.9  472.55</code></pre>
<p>By setting <code>which.time = .none</code> in <code>bal.tab()</code>,
we can focus on the overall balance assessment, which displays the
greatest imbalance for each covariate across time points. We can see
that our estimated weights balance all covariates all time points with
respect to means and variances. Now we can estimate our treatment
effects. We’ll sequentially simplify our model by checking whether
interaction terms are needed (implying that specific patterns of
treatment yield different outcomes), then by checking whether different
coefficients are needed for the treatments (implying that outcomes
depend on which treatments are received).</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;survey&quot;</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>d.w.msm <span class="ot">&lt;-</span> <span class="fu">svydesign</span>(<span class="sc">~</span><span class="dv">1</span>, <span class="at">weights =</span> Wmsm.out<span class="sc">$</span>weights,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> iptwExWide)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>full.fit <span class="ot">&lt;-</span> <span class="fu">svyglm</span>(outcome <span class="sc">~</span> tx1<span class="sc">*</span>tx2<span class="sc">*</span>tx3, <span class="at">design =</span> d.w.msm)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>main.effects.fit <span class="ot">&lt;-</span> <span class="fu">svyglm</span>(outcome <span class="sc">~</span> tx1 <span class="sc">+</span> tx2 <span class="sc">+</span> tx3, <span class="at">design =</span> d.w.msm)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.fit, main.effects.fit)</span></code></pre></div>
<pre><code>## Working (Rao-Scott+F) LRT for tx1:tx2 tx1:tx3 tx2:tx3 tx1:tx2:tx3
##  in svyglm(formula = outcome ~ tx1 * tx2 * tx3, design = d.w.msm)
## Working 2logLR =  7.689984 p= 0.10639 
## (scale factors:  1.3 1.1 0.96 0.65 );  denominator df= 992</code></pre>
<p>Based on the non-significant p-value, we don’t have to assume
specific treatment patterns yield different outcomes, but rather only
that which treatments received or the number of treatments received are
sufficient to explain variation in the outcome. Next we’ll narrow down
these options by comparing the main effects fit to one that constrains
the coefficients to be equal (implying that the cumulative number of
treatments received is what matters), as <span class="citation">Robins,
Hernán, and Brumback (<a href="#ref-robinsMarginalStructuralModels2000" role="doc-biblioref">2000</a>)</span> describe.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>cum.fit <span class="ot">&lt;-</span> <span class="fu">svyglm</span>(outcome <span class="sc">~</span> <span class="fu">I</span>(tx1<span class="sc">+</span>tx2<span class="sc">+</span>tx3), <span class="at">design =</span> d.w.msm)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(main.effects.fit, cum.fit)</span></code></pre></div>
<pre><code>## Working (Rao-Scott+F) LRT for tx1 tx2 tx3 - I(tx1 + tx2 + tx3)
##  in svyglm(formula = outcome ~ tx1 + tx2 + tx3, design = d.w.msm)
## Working 2logLR =  1.840286 p= 0.40005 
## (scale factors:  1 0.96 );  denominator df= 996</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(full.fit, cum.fit)</span></code></pre></div>
<pre><code>## Working (Rao-Scott+F) LRT for tx1 tx2 tx3 tx1:tx2 tx1:tx3 tx2:tx3 tx1:tx2:tx3 - I(tx1 + tx2 + tx3)
##  in svyglm(formula = outcome ~ tx1 * tx2 * tx3, design = d.w.msm)
## Working 2logLR =  9.504989 p= 0.15137 
## (scale factors:  1.3 1.2 1.1 1 0.73 0.58 );  denominator df= 992</code></pre>
<p>Based on the non-significant p-value, we can assume the effects of
each treatment are close enough to be treated as the same, indicating
that the number of treatments received is the relevant predictor of the
outcome. Now we can examine what that treatment effect is with
<code>summ()</code> in <code>jtools</code> (or
<code>summary()</code>).</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cum.fit)</span></code></pre></div>
<pre><code>## 
## Call:
## svyglm(formula = outcome ~ I(tx1 + tx2 + tx3), design = d.w.msm)
## 
## Survey design:
## svydesign(~1, weights = Wmsm.out$weights, data = iptwExWide)
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         0.13072    0.05412   2.416   0.0159 *  
## I(tx1 + tx2 + tx3) -0.15157    0.02734  -5.545 3.77e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 0.5307998)
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(cum.fit)</span></code></pre></div>
<pre><code>##                          2.5 %      97.5 %
## (Intercept)         0.02452672  0.23691596
## I(tx1 + tx2 + tx3) -0.20520895 -0.09792381</code></pre>
<p>For each additional treatment received, the outcome is expected to
decrease by 0.15 points. The confidence interval excludes 0, so there is
evidence of a treatment effect in the population.</p>
<p>There is more we can do, as well. We could have fit different types
of models to estimate the weights, and we could have stabilized the
weights with <code>stabilize = TRUE</code> or by including stabilization
factors in our weights using <code>num.formula</code> (see <span class="citation">Cole and Hernán (<a href="#ref-coleConstructingInverseProbability2008" role="doc-biblioref">2008</a>)</span> for more details on doing so).
There are other ways of computing confidence intervals for our effect
estimates (although model comparison is the most straightforward with
the method we used).</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-austinIntroductionPropensityScore2011" class="csl-entry">
Austin, Peter C. 2011. <span>“An Introduction to Propensity Score
Methods for Reducing the Effects of Confounding in Observational
Studies.”</span> <em>Multivariate Behavioral Research</em> 46 (3):
399–424. <a href="https://doi.org/10.1080/00273171.2011.568786">https://doi.org/10.1080/00273171.2011.568786</a>.
</div>
<div id="ref-austinMovingBestPractice2015" class="csl-entry">
Austin, Peter C., and Elizabeth A. Stuart. 2015. <span>“Moving Towards
Best Practice When Using Inverse Probability of Treatment Weighting
(<span>IPTW</span>) Using the Propensity Score to Estimate Causal
Treatment Effects in Observational Studies.”</span> <em>Statistics in
Medicine</em> 34 (28): 3661–79. <a href="https://doi.org/10.1002/sim.6607">https://doi.org/10.1002/sim.6607</a>.
</div>
<div id="ref-chanGloballyEfficientNonparametric2016" class="csl-entry">
Chan, Kwun Chuen Gary, Sheung Chi Phillip Yam, and Zheng Zhang. 2016.
<span>“Globally Efficient Non-Parametric Inference of Average Treatment
Effects by Empirical Balancing Calibration Weighting.”</span>
<em>Journal of the Royal Statistical Society: Series B (Statistical
Methodology)</em> 78 (3): 673–700. <a href="https://doi.org/10.1111/rssb.12129">https://doi.org/10.1111/rssb.12129</a>.
</div>
<div id="ref-coleConstructingInverseProbability2008" class="csl-entry">
Cole, Stephen R., and Miguel A Hernán. 2008. <span>“Constructing
<span>Inverse Probability Weights</span> for <span>Marginal Structural
Models</span>.”</span> <em>American Journal of Epidemiology</em> 168
(6): 656–64. <a href="https://doi.org/10.1093/aje/kwn164">https://doi.org/10.1093/aje/kwn164</a>.
</div>
<div id="ref-hainmuellerEntropyBalancingCausal2012" class="csl-entry">
Hainmueller, J. 2012. <span>“Entropy Balancing for Causal Effects:
<span>A</span> Multivariate Reweighting Method to Produce Balanced
Samples in Observational Studies.”</span> <em>Political Analysis</em> 20
(1): 25–46. <a href="https://doi.org/10.1093/pan/mpr025">https://doi.org/10.1093/pan/mpr025</a>.
</div>
<div id="ref-reifeisVarianceTreatmentEffect2020" class="csl-entry">
Reifeis, Sarah A., and Michael G. Hudgens. 2020. <span>“On Variance of
the Treatment Effect in the Treated Using Inverse Probability
Weighting.”</span> <em>arXiv:2011.11874 [Stat]</em>, November. <a href="https://arxiv.org/abs/2011.11874">https://arxiv.org/abs/2011.11874</a>.
</div>
<div id="ref-robinsMarginalStructuralModels2000" class="csl-entry">
Robins, James M., Miguel Ángel Hernán, and Babette Brumback. 2000.
<span>“Marginal Structural Models and Causal Inference in
Epidemiology.”</span> <em>Epidemiology</em> 11 (5): 550–60. <a href="https://doi.org/10.2307/3703997">https://doi.org/10.2307/3703997</a>.
</div>
<div id="ref-thoemmesPrimerInverseProbability2016" class="csl-entry">
Thoemmes, Felix J., and Anthony D. Ong. 2016. <span>“A Primer on Inverse
Probability of Treatment Weighting and Marginal Structural
Models.”</span> <em>Emerging Adulthood</em> 4 (1): 40–59. <a href="https://doi.org/10.1177/2167696815621645">https://doi.org/10.1177/2167696815621645</a>.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
